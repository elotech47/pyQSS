name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

jobs:
  test:
    name: Test on Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10", "3.11", "3.12"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel pybind11 pytest pytest-cov setuptools
    
    - name: Clean previous builds
      run: |
        rm -rf build/ dist/ *.egg-info/
        find . -name "*.so" -delete
        find . -name "__pycache__" -type d -exec rm -rf {} + || true
    
    - name: Build package
      run: |
        echo "Building package..."
        python -m build --verbose 2>&1 | tee build.log
        echo "Build completed"
        echo "Build log contents:"
        cat build.log
    
    - name: List build artifacts
      run: ls -la dist/
    
    - name: Check wheel contents
      run: |
        python -c "
        import zipfile
        import glob
        wheel_files = glob.glob('dist/*.whl')
        if wheel_files:
            with zipfile.ZipFile(wheel_files[0], 'r') as z:
                files = z.namelist()
                print('Wheel contents:')
                for f in sorted(files):
                    print(f'  {f}')
                cpp_ext = [f for f in files if f.endswith('.so') or f.endswith('.pyd')]
                print(f'C++ extensions found: {cpp_ext}')
                qss_py_files = [f for f in files if 'qss_py' in f]
                print(f'qss_py files found: {qss_py_files}')
        "
    
    - name: Install package from wheel
      run: |
        pip install dist/*.whl --force-reinstall --no-deps
        pip install numpy>=1.16.0  # Install dependencies separately
    
    - name: Verify package installation - detailed
      run: |
        echo "=== Python and pip info ==="
        python --version
        pip --version
        echo "=== Package location ==="
        python -c "import qss_integrator; print('qss_integrator.__file__:', qss_integrator.__file__)"
        echo "=== Package directory contents ==="
        python -c "
        import qss_integrator
        import os
        pkg_dir = os.path.dirname(qss_integrator.__file__)
        print(f'Package directory: {pkg_dir}')
        for root, dirs, files in os.walk(pkg_dir):
            level = root.replace(pkg_dir, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f'{indent}{os.path.basename(root)}/')
            subindent = ' ' * 2 * (level + 1)
            for file in files:
                print(f'{subindent}{file}')
        "
        echo "=== Module contents ==="
        python -c "import qss_integrator; print('qss_integrator contents:', dir(qss_integrator))"
    
    - name: Test C++ extension import
      run: |
        python -c "
        try:
            import qss_integrator.qss_py
            print('✓ C++ extension imported successfully')
            print('qss_py contents:', dir(qss_integrator.qss_py))
        except ImportError as e:
            print('✗ C++ extension import failed:', e)
            import sys
            print('Python path:', sys.path[:5])
            import qss_integrator
            import os
            pkg_dir = os.path.dirname(qss_integrator.__file__)
            print('Looking for .so files in package:')
            for root, dirs, files in os.walk(pkg_dir):
                for file in files:
                    if file.endswith(('.so', '.pyd')):
                        print(f'  Found: {os.path.join(root, file)}')
            raise
        "
    
    - name: Test main imports
      run: |
        python -c "
        from qss_integrator import QssIntegrator
        print('✓ QssIntegrator imported successfully')
        integrator = QssIntegrator()
        print('✓ QssIntegrator instantiated successfully')
        "
    
    - name: Run tests
      run: pytest tests/ -v --cov=qss_integrator --cov-report=xml
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build:
    name: Build wheels
    runs-on: ${{ matrix.os }}
    needs: test
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: [3.8, 3.9, "3.10", "3.11", "3.12"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake
    
    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install cmake
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel pybind11 setuptools
    
    - name: Build package
      run: python -m build
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist-${{ matrix.os }}-py${{ matrix.python-version }}
        path: dist/

  publish-testpypi:
    name: Publish to TestPyPI
    runs-on: ubuntu-latest
    needs: [test, build]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: dist/
    
    - name: Combine artifacts
      run: |
        mkdir -p dist-combined
        find dist -name "*.whl" -exec cp {} dist-combined/ \;
        find dist -name "*.tar.gz" -exec cp {} dist-combined/ \;
        ls -la dist-combined/
    
    - name: Publish to TestPyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.TESTPYPI_API_TOKEN }}
      run: |
        pip install twine
        twine upload --repository testpypi dist-combined/*

  publish-pypi:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [test, build]
    if: github.event_name == 'release' && github.event.action == 'published'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: dist/
    
    - name: Combine artifacts
      run: |
        mkdir -p dist-combined
        find dist -name "*.whl" -exec cp {} dist-combined/ \;
        find dist -name "*.tar.gz" -exec cp {} dist-combined/ \;
        ls -la dist-combined/
    
    - name: Publish to PyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
      run: |
        pip install twine
        twine upload dist-combined/*